---
title: "Nöral Makine Çeviri Modelini Görselleştirme (Attention Mekanizması ile Seq2seq Modeli)"
date: 2018-09-24
tags: [nlp,ml, seq2seq]
header:
  image: ""
excerpt: "nlp, ml, seq2seq"
---

<p align="justify" >"Nöral Makine Çeviri Modelini Görselleştirme (Attention Mekanizması ile Seq2seq Modeli)" adlı makaleye ulaşmak ve okumak isterseniz
bu [linki](https://medium.com/@SenemAktas/n%C3%B6ral-makine-%C3%A7eviri-modelini-g%C3%B6rselle%C5%9Ftirme-seq2seq-modelinin-attention-mekanizmas%C4%B1-b12581b5a1df) kullanabilirsiniz. </p>

<p align="justify" > Bu makale, [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) Türkçe çevirisidir. Kaynak, aslında MIT sınıflarında kullanılan Jay Alammar [@JayAlammar](https://twitter.com/JayAlammar) tarafından yazılmış bir blog makalesidir.</p>

And here's some *italics*

Here's some **bold** text.

[link](https://medium.com/@SenemAktas/n%C3%B6ral-makine-%C3%A7eviri-modelini-g%C3%B6rselle%C5%9Ftirme-seq2seq-modelinin-attention-mekanizmas%C4%B1-b12581b5a1df)

Here's a bulleted list:
* First item
+ Second item
- Third item

Here's a numbered list:
1. First
2. Second
3. Third

